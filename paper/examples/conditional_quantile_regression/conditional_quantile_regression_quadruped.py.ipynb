{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-01T06:42:28.477573Z",
     "start_time": "2025-04-01T06:42:28.398073Z"
    }
   },
   "source": [
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "from symm_rep_learn.models.multivariateCQR import get_coverage, get_set_size\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import BatchNorm1d, Linear, Sequential\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from symm_rep_learn.inference.encp import ENCPConditionalCDF\n",
    "from symm_rep_learn.inference.ncp import NCPConditionalCDF\n",
    "\n",
    "cwd = pathlib.Path(os.getcwd())\n",
    "root_dir = cwd.parent.parent.parent\n",
    "sys.path.append(str(cwd))\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "from paper.experiments.GRF_uncertainty_regression import get_uc_model, plot_gt_and_quantiles, get_proprioceptive_data\n",
    "\n",
    "# Paths to exemplars form the experiment which we will load.\n",
    "ncp_path = root_dir / 'paper/results/GRF_regression/kinE_U_go1/robot=go1_lr=0.0001_bs=2048_pat=25_NCP_hu=512_hl=4_act=ELU_resY=False_lstsq=True/gamma=50 seed=1'\n",
    "encp_path = root_dir / 'paper/results/GRF_regression/kinE_U_go1/robot=go1_lr=0.0001_bs=2048_pat=25_ENCP_hu=512_hl=4_act=ELU_resY=False_lstsq=True/gamma=50 seed=1'\n",
    "cqr_path = root_dir / 'paper/results/GRF_regression/kinE_U_go1/robot=go1_lr=0.0001_bs=2048_pat=25_CQR_hu=512_hl=4_act=ELU_resY=False_lstsq=True/ seed=1'\n",
    "paths = {'ncp': ncp_path, 'encp': encp_path, 'cqr': cqr_path}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T06:42:40.369920Z",
     "start_time": "2025-04-01T06:42:31.064772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import escnn\n",
    "from escnn.nn import FieldType\n",
    "\n",
    "# Load experiment runs configurations_____________________________________________\n",
    "configs = {}\n",
    "for model_name, model_path in paths.items():\n",
    "    configs[model_name] = OmegaConf.load(model_path/ '.hydra' / 'config.yaml')\n",
    "\n",
    "# Load dataset______________________________________________________________________\n",
    "cfg = configs['ncp']   # Any config will do.\n",
    "cfg.dataset.path = root_dir / cfg.dataset.path\n",
    "samples, datasets, (rep_x, rep_y), x_moments, y_moments, y_obs_dims = get_proprioceptive_data(configs['ncp'])\n",
    "(x_train, y_train), (x_val, y_val), (x_test, y_test) = samples\n",
    "train_ds, val_ds, test_ds = datasets\n",
    "\n",
    "G = rep_x.group\n",
    "# lat_rep = G.regular_representation\n",
    "x_type = FieldType(gspace=escnn.gspaces.no_base_space(G), representations=[rep_x])\n",
    "y_type = FieldType(gspace=escnn.gspaces.no_base_space(G), representations=[rep_y])\n",
    "\n",
    "# Load models______________________________________________________________________\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "models = {}\n",
    "for model_name, model_cfg in configs.items():\n",
    "    models[model_name] = get_uc_model(model_cfg, x_type, y_type)\n",
    "    best_path = paths[model_name] / 'last.ckpt'\n",
    "    state_dict = torch.load(best_path, map_location=device, weights_only=True)['state_dict']\n",
    "    state_dict = {k.replace('model.', '', 1): v for k, v in state_dict.items()}\n",
    "    models[model_name].load_state_dict(state_dict)\n",
    "    models[model_name].to(device).eval()\n",
    "    print(f\"- Loaded trained {model_name}\")\n",
    "    print(f\"\\tNumber of parameters: {sum(p.numel() for p in models[model_name].parameters())}\")"
   ],
   "id": "742458bd94bf7381",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danfoa/Projects/MorphoSymm/morpho_symm/utils/robot_utils.py:152: UserWarning: Representation Q_js found while loading the robot go1. This happens when you load multiple robots in the same session. The old representation will be overwritten.\n",
      "  warnings.warn(\n",
      "/home/danfoa/Projects/MorphoSymm/morpho_symm/utils/robot_utils.py:152: UserWarning: Representation TqQ_js found while loading the robot go1. This happens when you load multiple robots in the same session. The old representation will be overwritten.\n",
      "  warnings.warn(\n",
      "/home/danfoa/Projects/MorphoSymm/morpho_symm/utils/robot_utils.py:152: UserWarning: Representation E3 found while loading the robot go1. This happens when you load multiple robots in the same session. The old representation will be overwritten.\n",
      "  warnings.warn(\n",
      "/home/danfoa/Projects/MorphoSymm/morpho_symm/utils/robot_utils.py:152: UserWarning: Representation R3 found while loading the robot go1. This happens when you load multiple robots in the same session. The old representation will be overwritten.\n",
      "  warnings.warn(\n",
      "/home/danfoa/Projects/MorphoSymm/morpho_symm/utils/robot_utils.py:152: UserWarning: Representation R3_pseudo found while loading the robot go1. This happens when you load multiple robots in the same session. The old representation will be overwritten.\n",
      "  warnings.warn(\n",
      "/home/danfoa/Projects/MorphoSymm/morpho_symm/utils/robot_utils.py:152: UserWarning: Representation E3_pseudo found while loading the robot go1. This happens when you load multiple robots in the same session. The old representation will be overwritten.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- qpos_js: C2|[Q_js]:12\n",
      "- qvel_js: C2|[TqQ_js]:12\n",
      "- base_lin_acc:base: C2|[R3]:3\n",
      "- base_lin_vel:base: C2|[R3]:3\n",
      "- base_lin_vel_err:base: C2|[R3]:3\n",
      "- base_ang_vel:base: C2|[R3_pseudo]:3\n",
      "- base_ang_vel_err:base: C2|[R3_pseudo]:3\n",
      "- gravity_vector:base: C2|[R3]:3\n",
      "- feet_vel:base: C2|[Rd_on_limbs]:12\n",
      "- tau_ctrl_setpoint: C2|[TqQ_js]:12\n",
      "- work: C2|[irrep_0]:1\n",
      "- kinetic_energy: C2|[irrep_0]:1\n",
      "- Loaded trained ncp\n",
      "\tNumber of parameters: 1677312\n",
      "- Loaded trained encp\n",
      "\tNumber of parameters: 873472\n",
      "- Loaded trained cqr\n",
      "\tNumber of parameters: 1181952\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Configure the models for conditional quantile regression",
   "id": "13f57255579e3992"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T06:42:53.354668Z",
     "start_time": "2025-04-01T06:42:40.427134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "alpha = cfg.alpha   # All models configured with the same alpha\n",
    "encp_ccdf = ENCPConditionalCDF(\n",
    "    model=models['encp'], y_train=y_type(y_train), support_discretization_points=500, lstsq=True\n",
    "    )\n",
    "ncp_ccdf = NCPConditionalCDF(\n",
    "    model=models['ncp'], y_train=y_train, support_discretization_points=500, lstsq=True\n",
    "    )\n",
    "# Query the quantiles for all the testing set\n",
    "q_low_encp, q_high_encp = encp_ccdf.conditional_quantiles(x_cond=x_type(x_test), alpha=alpha)\n",
    "q_low_ncp, q_high_ncp = ncp_ccdf.conditional_quantiles(x_cond=x_test, alpha=alpha)\n",
    "q_low_cqr, q_high_cqr = models['cqr'](x_test)  # CQR model is already a quantile regression model.\n",
    "\n",
    "quantiles = {}\n",
    "coverage, set_size = {}, {}\n",
    "for model_name in ['encp', 'ncp', 'cqr']:\n",
    "    q_low, q_high = locals()[f'q_low_{model_name}'], locals()[f'q_high_{model_name}']\n",
    "    q_low = torch.tensor(q_low, device=device, dtype=y_train.dtype)\n",
    "    q_high = torch.tensor(q_high, device=device, dtype=y_train.dtype)\n",
    "    quantiles[model_name] = (q_low, q_high)\n",
    "    coverage[model_name] = get_coverage(q_low, q_high, y_test)\n",
    "    set_size[model_name] = get_set_size(q_low, q_high)\n",
    "# Print a table with the coverage and set size of the models\n",
    "pd.DataFrame({'coverage': coverage, 'set_size': set_size})"
   ],
   "id": "681d23fef8d4cdf6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14023/3256168475.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  q_low = torch.tensor(q_low, device=device, dtype=y_train.dtype)\n",
      "/tmp/ipykernel_14023/3256168475.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  q_high = torch.tensor(q_high, device=device, dtype=y_train.dtype)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "            coverage        set_size\n",
       "encp  tensor(0.6400)  tensor(1.9614)\n",
       "ncp   tensor(0.9172)  tensor(1.2942)\n",
       "cqr   tensor(0.5755)  tensor(0.1583)"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coverage</th>\n",
       "      <th>set_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>encp</th>\n",
       "      <td>tensor(0.6400)</td>\n",
       "      <td>tensor(1.9614)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ncp</th>\n",
       "      <td>tensor(0.9172)</td>\n",
       "      <td>tensor(1.2942)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cqr</th>\n",
       "      <td>tensor(0.5755)</td>\n",
       "      <td>tensor(0.1583)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "4bcc845d600ec2d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1541b094df75bd77"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
